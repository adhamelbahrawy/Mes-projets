{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import utility as u\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"synthetic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns.values.tolist()\n",
    "\n",
    "features = cols[0:14] \n",
    "label = cols[14]\n",
    "\n",
    "X = df[features]\n",
    "y = df[label]\n",
    "y = pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(object):\n",
    "    def __init__(self, X_train = None, y_train = None, X_test = None, y_test = None,\n",
    "             hidden_layer_sizes=(4,), activation='identity', learning_rate=0.1, epoch=10):\n",
    "        self.X_train =  X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        self.n_layers = len(hidden_layer_sizes)\n",
    "        self.weights = [None] * (self.n_layers +1)\n",
    "        self.bias = [None] * (self.n_layers +1)\n",
    "        self.activation = getattr(u.Utility, activation) # activation(np.arrange(12).reshape(3,4))\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epoch = epoch\n",
    "        self.weights_initialization(X_train, y_train)\n",
    "        \n",
    "    def weights_initialization(self, x, y):\n",
    "        self.weights[0] = np.random.uniform(-1.0, 1.0, (self.hidden_layer_sizes[0],x[0].shape[0]))\n",
    "        self.bias[0] = np.random.uniform(0.0, 0.0, (self.hidden_layer_sizes[0], 1))\n",
    "        for i in range(1, len(self.weights)):\n",
    "            if(i == len(self.weights) - 1):\n",
    "                self.weights[i] = np.random.uniform(-1.0, 1.0, (len(y[0]),self.weights[i-1].shape[0]))\n",
    "                self.bias[i] = np.random.uniform(0.0, 0.0, (len(y[0]), 1))\n",
    "                return\n",
    "            self.weights[i] = np.random.uniform(-1.0, 1.0, (self.hidden_layer_sizes[i],self.weights[i-1].shape[0]))\n",
    "            self.bias[i] = np.random.uniform(0.0, 0.0, (self.hidden_layer_sizes[i], 1))\n",
    "            \n",
    "    def propa_avant(self):\n",
    "        Z = self.weights[0]*X_train[0] + self.bias[0]\n",
    "        A = self.activation(Z)\n",
    "        for i in range(1, self.n_layers+1):\n",
    "            Z = self.weights[i] * A + self.bias[i]\n",
    "            if (i == self.n_layers):\n",
    "                A = u.softmax(Z)\n",
    "                return A #il serait bien de retourner un tulpe contenant A et l'erreur A - Y chapeau\n",
    "            else :\n",
    "                A = self.activation(Z)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
